{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d904f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Configuração de exibição\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Carregamento e Engenharia de Features\n",
    "try:\n",
    "    df_raw = pd.read_csv('dados_consumo_simulados(2).csv')\n",
    "    print(\"Dados carregados com sucesso. Primeiras 5 linhas:\")\n",
    "    print(df_raw.head())\n",
    "\n",
    "    # --- Pré-processamento e Engenharia de Features ---\n",
    "\n",
    "    # 1. Limpeza/Cálculo de Quantidade Absoluta (Se 'quantidade' é o valor do consumo/estoque)\n",
    "    # Assumimos que o problema se refere à gestão de estoque/consumo por Unidade e Material\n",
    "    df_raw['quantidade_abs'] = df_raw['quantidade'].abs()\n",
    "\n",
    "    # 2. Criação da Variável Alvo Contínua (Regressão)\n",
    "    # Exemplo: Consumo Total Mínimo do Material\n",
    "    df_agg = df_raw.groupby(['unidade', 'material']).agg(\n",
    "        CONSUMO_REAL=('quantidade_abs', 'sum'),\n",
    "        qtd_transacoes=('quantidade_abs', 'count'),\n",
    "        media_transacao=('quantidade_abs', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # 3. Criação da Variável Alvo Binária (Classificação)\n",
    "    # Problema: Atraso na Entrega/Necessidade Crítica (ex: alto consumo).\n",
    "    # Vamos simular o 'ATRASO_ENTREGA' para as unidades/materiais com consumo acima do 75º percentil.\n",
    "    consumo_q75 = df_agg['CONSUMO_REAL'].quantile(0.75)\n",
    "    df_agg['ATRASO_ENTREGA'] = (df_agg['CONSUMO_REAL'] > consumo_q75).astype(int)\n",
    "    print(f\"\\nVariável 'ATRASO_ENTREGA' criada: 1 se CONSUMO_REAL > {consumo_q75:.2f} (Top 25% de Consumo).\")\n",
    "    print(df_agg.head())\n",
    "\n",
    "    # 4. Preparação das Features para Modelagem (One-Hot Encoding)\n",
    "    X = df_agg.drop(columns=['CONSUMO_REAL', 'ATRASO_ENTREGA'])\n",
    "    y_class = df_agg['ATRASO_ENTREGA']\n",
    "    y_reg = df_agg['CONSUMO_REAL']\n",
    "\n",
    "    # Separando features categóricas e numéricas para pré-processamento\n",
    "    categorical_features = ['unidade', 'material']\n",
    "    numerical_features = ['qtd_transacoes', 'media_transacao']\n",
    "\n",
    "    # Criação do Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Aplicação do Preprocessor e Divisão dos Dados\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "    feature_names = numerical_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
    "    X_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "    # Divisão para Classificação\n",
    "    X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "        X_df, y_class, test_size=0.3, random_state=42, stratify=y_class\n",
    "    )\n",
    "    # Divisão para Regressão (usamos os mesmos X_df e y_reg)\n",
    "    X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "        X_df, y_reg, test_size=0.3, random_state=42\n",
    "    )\n",
    "    features = feature_names # Atualiza a lista de features para o código de modelagem\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: O arquivo 'dados_consumo_simulados(2).csv' não foi encontrado. Verifique o caminho.\")\n",
    "    # Adicione `return` se quiser parar a execução em caso de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9374053",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Testando valores de K de 1 a 15\n",
    "k_range = range(1, 16)\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_class, y_train_class, cv=5, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "# O melhor K é o que maximiza a acurácia média da validação cruzada\n",
    "best_k = k_range[np.argmax(k_scores)]\n",
    "print(f\"O melhor valor de K encontrado é: {best_k}\")\n",
    "\n",
    "# Modelo KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_model.fit(X_train_class, y_train_class)\n",
    "y_pred_knn = knn_model.predict(X_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928db2e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "acc_knn = accuracy_score(y_test_class, y_pred_knn)\n",
    "prec_knn = precision_score(y_test_class, y_pred_knn)\n",
    "rec_knn = recall_score(y_test_class, y_pred_knn)\n",
    "f1_knn = f1_score(y_test_class, y_pred_knn)\n",
    "\n",
    "print(\"\\n--- Métricas de Avaliação KNN ---\")\n",
    "print(f\"Acurácia: {acc_knn:.4f}\")\n",
    "print(f\"Precisão: {prec_knn:.4f}\")\n",
    "print(f\"Recall: {rec_knn:.4f}\")\n",
    "print(f\"F1-Score: {f1_knn:.4f}\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1538cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "acc_knn = accuracy_score(y_test_class, y_pred_knn)\n",
    "prec_knn = precision_score(y_test_class, y_pred_knn)\n",
    "rec_knn = recall_score(y_test_class, y_pred_knn)\n",
    "f1_knn = f1_score(y_test_class, y_pred_knn)\n",
    "\n",
    "print(\"\\n--- Métricas de Avaliação KNN ---\")\n",
    "print(f\"Acurácia: {acc_knn:.4f}\")\n",
    "print(f\"Precisão: {prec_knn:.4f}\")\n",
    "print(f\"Recall: {rec_knn:.4f}\")\n",
    "print(f\"F1-Score: {f1_knn:.4f}\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090171a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Modelo de Regressão Logística\n",
    "logreg_model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "logreg_model.fit(X_train_class, y_train_class)\n",
    "y_pred_logreg = logreg_model.predict(X_test_class)\n",
    "\n",
    "# Interpretação dos Coeficientes\n",
    "print(\"\\n--- Interpretação dos Coeficientes da Regressão Logística ---\")\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coeficiente': logreg_model.coef_[0],\n",
    "    'Odds Ratio (exp(Coef))': np.exp(logreg_model.coef_[0])\n",
    "})\n",
    "coef_df = coef_df.sort_values(by='Odds Ratio (exp(Coef))', ascending=False).reset_index(drop=True)\n",
    "print(coef_df.head(10)) # Exibe as 10 mais relevantes\n",
    "\n",
    "# Interpretação\n",
    "print(\"\\nInterpretação:\")\n",
    "print(\"Features com Odds Ratio (OR) > 1 aumentam a chance de 'ATRASO_ENTREGA'.\")\n",
    "print(\"Features com OR < 1 diminuem a chance de 'ATRASO_ENTREGA'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce36443",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "acc_logreg = accuracy_score(y_test_class, y_pred_logreg)\n",
    "prec_logreg = precision_score(y_test_class, y_pred_logreg)\n",
    "rec_logreg = recall_score(y_test_class, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test_class, y_pred_logreg)\n",
    "\n",
    "comparacao_class = pd.DataFrame({\n",
    "    'Modelo': ['KNN', 'Regressão Logística'],\n",
    "    'Acurácia': [acc_knn, acc_logreg],\n",
    "    'F1-Score': [f1_knn, f1_logreg]\n",
    "}).set_index('Modelo')\n",
    "\n",
    "print(\"\\n--- Comparação de Métricas de Classificação (KNN vs. LogReg) ---\")\n",
    "print(comparacao_class)\n",
    "\n",
    "# Discussão\n",
    "print(\"\\nDiscussão - Vantagens:\")\n",
    "print(\"KNN: Bom para fronteiras complexas, mas 'caixa preta'.\")\n",
    "print(\"Regressão Logística: Oferece interpretabilidade via Odds Ratios, ideal para entender a influência de cada material/unidade no risco de atraso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47e8b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Modelo de Regressão Linear Simples (Base)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Modelo Ridge (L2 Regularization)\n",
    "alpha_ridge = 1.0 # Exemplo de Alpha\n",
    "ridge_model = Ridge(alpha=alpha_ridge)\n",
    "ridge_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Comparação dos Coeficientes\n",
    "coef_comp_reg = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Linear_Reg_Coef': lin_reg.coef_,\n",
    "    'Ridge_Coef': ridge_model.coef_\n",
    "})\n",
    "\n",
    "print(f\"\\n--- Comparação de Coeficientes: Regressão Linear vs. Ridge (Alpha={alpha_ridge}) ---\")\n",
    "print(coef_comp_reg.sort_values(by='Linear_Reg_Coef', ascending=False).head(5))\n",
    "\n",
    "# Discussão\n",
    "print(\"\\nDiscussão - Efeito da Regularização Ridge:\")\n",
    "print(\"Ridge encolhe a magnitude dos coeficientes, mas não os zera. Isso estabiliza o modelo, prevenindo que features pouco importantes dominem, sem eliminá-las.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3e688",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Modelo Lasso (L1 Regularization)\n",
    "alpha_lasso = 1.0 # Valor pode ser ajustado. Um valor maior força mais zeros.\n",
    "lasso_model = Lasso(alpha=alpha_lasso, max_iter=10000)\n",
    "lasso_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Comparação dos Coeficientes\n",
    "coef_comp_reg['Lasso_Coef'] = lasso_model.coef_\n",
    "\n",
    "print(f\"\\n--- Comparação de Coeficientes: Ridge vs. Lasso (Alpha={alpha_lasso}) ---\")\n",
    "print(coef_comp_reg.sort_values(by='Linear_Reg_Coef', ascending=False))\n",
    "\n",
    "# Variáveis excluídas (coeficiente = 0)\n",
    "excluded_vars_lasso = coef_comp_reg[coef_comp_reg['Lasso_Coef'].round(4) == 0]['Feature'].tolist()\n",
    "\n",
    "# Discussão\n",
    "print(\"\\nDiscussão - Efeito da Regularização Lasso:\")\n",
    "print(\"Lasso zera coeficientes de features irrelevantes (seleção automática de variáveis).\")\n",
    "if excluded_vars_lasso:\n",
    "    print(f\"Variáveis excluídas (Coeficiente ~ 0) pelo Lasso: {len(excluded_vars_lasso)} variáveis.\")\n",
    "else:\n",
    "    print(\"Nenhuma variável foi totalmente excluída com este alpha.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0f577",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Regressão Polinomial de Grau 2\n",
    "degree = 2\n",
    "poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_reg)\n",
    "X_test_poly = poly.transform(X_test_reg)\n",
    "\n",
    "# Modelo de Regressão Linear no novo conjunto\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train_reg)\n",
    "y_pred_poly = poly_reg.predict(X_test_poly)\n",
    "\n",
    "# Métricas\n",
    "y_pred_lin = lin_reg.predict(X_test_reg)\n",
    "r2_lin = r2_score(y_test_reg, y_pred_lin)\n",
    "r2_poly = r2_score(y_test_reg, y_pred_poly)\n",
    "\n",
    "print(f\"\\n--- Comparação de Métricas de Regressão Contínua ---\")\n",
    "print(f\"Regressão Linear Simples: R²={r2_lin:.4f}\")\n",
    "print(f\"Regressão Polinomial (Grau {degree}): R²={r2_poly:.4f}\")\n",
    "\n",
    "# Avaliação\n",
    "if r2_poly > r2_lin:\n",
    "    print(\"Avaliação: Houve melhora. O modelo Polinomial capturou melhor as relações não-lineares.\")\n",
    "else:\n",
    "    print(\"Avaliação: Não houve melhora significativa ou o desempenho piorou, sugerindo que as relações são predominantemente lineares.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b273a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Função para avaliar Classificadores\n",
    "def evaluate_classifier(y_test, y_pred, model_name):\n",
    "    return {\n",
    "        'Modelo': model_name,\n",
    "        'Acurácia': accuracy_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# 1. Árvore de Decisão\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "dt_model.fit(X_train_class, y_train_class)\n",
    "metrics_dt = evaluate_classifier(y_test_class, dt_model.predict(X_test_class), 'Árvore de Decisão')\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
    "rf_model.fit(X_train_class, y_train_class)\n",
    "metrics_rf = evaluate_classifier(y_test_class, rf_model.predict(X_test_class), 'Random Forest')\n",
    "\n",
    "comparacao_tree = pd.DataFrame([metrics_dt, metrics_rf]).set_index('Modelo')\n",
    "\n",
    "print(\"\\n--- Comparação de Desempenho: Árvore de Decisão vs. Random Forest ---\")\n",
    "print(comparacao_tree)\n",
    "\n",
    "# Discussão\n",
    "print(\"\\nDiscussão - Interpretabilidade e Desempenho:\")\n",
    "print(\"Árvore de Decisão: ALTA interpretabilidade (regras claras).\")\n",
    "print(\"Random Forest: Geralmente melhor desempenho, pois reduz a variância (mais estável), mas é um modelo mais 'caixa preta'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593bd8f9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Consolidação de Métricas de Classificação\n",
    "all_class_metrics = pd.DataFrame([\n",
    "    evaluate_classifier(y_test_class, y_pred_knn, 'KNN'),\n",
    "    evaluate_classifier(y_test_class, y_pred_logreg, 'Regressão Logística'),\n",
    "    metrics_dt, metrics_rf\n",
    "])\n",
    "all_class_metrics = all_class_metrics.sort_values(by='F1-Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\\n--- Relatório Executivo - Comparação de Modelos ---\")\n",
    "\n",
    "print(\"\\nModelos de Classificação (Atraso na Entrega - Y_Binário):\")\n",
    "print(all_class_metrics)\n",
    "\n",
    "print(\"\\nModelos de Regressão Contínua (Consumo Real - Y_Contínuo):\")\n",
    "reg_metrics = pd.DataFrame({\n",
    "    'Modelo': ['Linear Simples', 'Ridge (L2)', 'Lasso (L1)', f'Polinomial (Grau {degree})'],\n",
    "    'R²': [r2_lin, r2_score(y_test_reg, ridge_model.predict(X_test_reg)), r2_score(y_test_reg, lasso_model.predict(X_test_reg)), r2_poly],\n",
    "})\n",
    "reg_metrics = reg_metrics.sort_values(by='R²', ascending=False).reset_index(drop=True)\n",
    "print(reg_metrics)\n",
    "\n",
    "# Recomendação Final\n",
    "best_class_model = all_class_metrics.iloc[0]\n",
    "\n",
    "print(\"\\n--- Recomendação Final ---\")\n",
    "print(f\"Melhor Abordagem para o Desafio de Classificação (Atraso): **{best_class_model['Modelo']}**\")\n",
    "print(\"Justificativa:\")\n",
    "if best_class_model['Modelo'] == 'Regressão Logística':\n",
    "    print(\"Recomendamos a Regressão Logística, pois, além do bom desempenho, ela oferece a **máxima interpretabilidade** para entender quais materiais/unidades mais contribuem para o risco de atraso (Odds Ratios). Isso é fundamental para a tomada de decisão operacional e intervenções.\")\n",
    "else:\n",
    "    print(f\"O **{best_class_model['Modelo']}** apresentou o melhor F1-Score/Acurácia. Ele é recomendado se o **desempenho preditivo bruto for a prioridade**, pois tende a ser mais robusto em dados complexos, mesmo que seja menos interpretável que a Regressão Logística.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
